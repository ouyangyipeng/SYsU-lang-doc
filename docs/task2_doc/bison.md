# 使用bison完成实验二
以复活版本的为例。

## 相关知识
### bison介绍
flex和bison进行配合使用，可以完成词法分析和语法分析。

输入一个文件，flex可以对该文件进行正则表达式的匹配，从而生成一系列的token流（这个大家在实验一中已经很清楚了）。

而lex生成每一个token之后，将其传给bison进行处理：bison会对当前传入的token进行语法分析，即文法的匹配，并进行相应移进归约操作，从而完成语法分析。

同时，我们可以在bison进行移进归约操作的时候，进行自定义语义动作，从而可以完成语法分析。

bison的使用方式很简单，同学们可以看下述链接？

### ASG（抽象语法图）介绍
相比起AST抽象语法树，在本实验中使用ASG抽象语法图更为恰当和合适（类似于AST，只是其的一种简化or变体，更能将其方便的json的转化和输出）。
同学们可以看下述链接？

## 总体思路(main.cpp)
以main.cpp为入口，实验2首先进行语法分析：`yyparse`（在其中进行填充ASG的结构），然后进行类型检查`typing(*par::gTranslationUnit)`，最后将asg生成json文件`asg2json`，并且写入指定文件。

在语法分析中，bison的`yyparse`中有下面的逻辑：


- 由于实验2以复活版本的进行实验，因此输入的task1-answer，同学们可以看下其中的一个文件：`/workspaces/SYsU-lang/build/test/task1/functional-0/000_main.sysu.c/answer.txt`，如下图所示

![task1-answer](../images/bison/task1-answer.png)

- bison会读取词法分析lex中的传入的token（lex每读取一个，就会传给bison进行语法分析），因此将上述文件输入到实验2中，此时词法分析lex相关部分代码比起实验一会发生变化，不过这一部分的代码目前已经写好了，同学们可以自行查看。
（其逻辑是：相比于实验一的输入直接是源文件从而进行相关的各个token的匹配，实验二复活版本将匹配上述输入文件的每一行，然后对每一行进行处理，提取出每行的第一个单词（tokenId）和每行的第二个单词中的引号内容（tokenValue）。例如，以一行为例，识别处的token，其tokenId为int，其tokenValue为引号内的内容，也为int。）
- bison拿到该token后，首先进行文法的匹配，进行移进归约操作，而后在每个移进归约的过程中完成用户自定义的语义动作，在本实验中，我们是生成并填充ASG结构。

在类型检查中，`typing`则将对生成的ASG中的每一个结构进行类型检查，如果不通过该类型检查，程序就会停止。同学可以利用这个方便地进行查错，判断自己到底是哪个类型没有写对。

在ASG生成json文件中，`asg2json`将在yyparse中生成并通过类型检查的ASG结构进行输出并打印。

而类型检查和ASG生成json文件的部分,已经进行了实现,同学们只要负责语法分析中的文法撰写和语义动作撰写(填充ASG)即可.

## 文件结构说明
对实验整体的

## 代码说明和解析



### 以一个文法为例子说明



## 如何debug
### 断点
有些情况不适用

### 日志文件进行输出
更能进行问题定位





## 可能会遇到的坑点

### 指针问题